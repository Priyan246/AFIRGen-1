# Concurrency Testing Guide

## Overview
This guide explains how to test the AFIRGen system's ability to handle 10 concurrent FIR generation requests.

## Prerequisites

### 1. System Requirements
- Docker and Docker Compose installed
- Python 3.8+ installed
- At least 8GB RAM available
- 4+ CPU cores recommended

### 2. Install Test Dependencies

```bash
# Install Python testing dependencies
pip install -r test_requirements.txt
```

This installs:
- `httpx` - Async HTTP client for testing
- `pytest` - Testing framework
- `pytest-asyncio` - Async test support

### 3. Start Services

```bash
# Start all services
docker-compose up -d

# Wait for services to be healthy (2-3 minutes for model loading)
docker-compose ps

# Check logs if needed
docker-compose logs -f fir_pipeline
```

### 4. Verify Services are Healthy

```bash
# Check main backend health
curl http://localhost:8000/health

# Expected output should show "status": "healthy" or "degraded"
```

## Running Concurrency Tests

### Test 1: Basic Concurrency Test

Tests 10 concurrent FIR generation requests:

```bash
python test_concurrency.py
```

**Expected Output:**
```
==============================================================
Concurrent Load Test - 10 Requests
==============================================================

System Health Check
==============================================================
Overall Status: healthy
Model Server: healthy
ASR/OCR Server: healthy
Database: connected

Concurrency Configuration:
  Max Concurrent Requests: 15
  Max Concurrent Model Calls: 10
  HTTP Pool Size: 20
==============================================================

Starting 10 concurrent FIR generation requests...

âœ… Request 1 completed in 18.45s
âœ… Request 2 completed in 19.12s
...
âœ… Request 10 completed in 20.34s

==============================================================
Concurrency Test Results
==============================================================
Total Duration: 22.34s
Requests: 10
Successful: 10
Failed: 0
Success Rate: 100.0%

Request Duration Statistics:
  Average: 19.23s
  Min: 18.45s
  Max: 20.67s
  Median: 19.15s

âœ… TEST PASSED - System handled 10 concurrent requests
==============================================================

ðŸ“Š Results saved to concurrency_test_results.json
```

**Success Criteria:**
- âœ… All 10 requests complete successfully
- âœ… Success rate: 100%
- âœ… Average duration: < 30 seconds
- âœ… No timeout errors
- âœ… No database connection errors

### Test 2: Performance Test (Single Request)

Tests single request performance:

```bash
python test_performance.py
```

**Expected Output:**
```
==============================================================
FIR Generation Performance Test
==============================================================

1. Checking service health...
Health Status: healthy
  Model Server: healthy
  ASR/OCR Server: healthy

2. Starting FIR processing...
âœ… Process step completed in 0.15s

3. Validating transcript...
âœ… transcript_validation completed in 3.45s

4. Validating summary...
âœ… summary_validation completed in 4.23s

5. Validating violations...
âœ… violations_validation completed in 5.67s

6. Validating FIR narrative...
âœ… narrative_validation completed in 3.89s

7. Final review...
âœ… final_review completed in 2.34s

==============================================================
Performance Test Results
==============================================================
Total Time: 19.73s
Target: 30.00s
Status: âœ… PASS

Step Breakdown:
  process                  :   0.15s
  transcript_validation    :   3.45s
  summary_validation       :   4.23s
  violations_validation    :   5.67s
  narrative_validation     :   3.89s
  final_review             :   2.34s
==============================================================

âœ… FIR Generated: FIR-a1b2c3d4-20240115103045

âœ… Performance test PASSED - FIR generation under 30 seconds
```

## Test Scenarios

### Scenario 1: Normal Load (10 concurrent requests)

```bash
# Run default test
python test_concurrency.py
```

**Expected:** All requests succeed in 20-30 seconds total

### Scenario 2: High Load (15 concurrent requests)

Edit `test_concurrency.py`:
```python
NUM_CONCURRENT_REQUESTS = 15
```

```bash
python test_concurrency.py
```

**Expected:** 
- All 15 requests succeed
- Some requests may queue (semaphore limit)
- Total duration: 30-40 seconds

### Scenario 3: Stress Test (20+ concurrent requests)

Edit `test_concurrency.py`:
```python
NUM_CONCURRENT_REQUESTS = 20
```

```bash
python test_concurrency.py
```

**Expected:**
- Requests queue due to semaphore limits
- All requests eventually succeed
- Total duration: 40-60 seconds
- System remains stable

### Scenario 4: Sustained Load

Run multiple test iterations:

```bash
# Run 5 iterations with 10 concurrent requests each
for i in {1..5}; do
    echo "Iteration $i"
    python test_concurrency.py
    sleep 10
done
```

**Expected:**
- All iterations pass
- Consistent performance across iterations
- No memory leaks or resource exhaustion

## Monitoring During Tests

### 1. System Resources

```bash
# Monitor Docker container resources
docker stats

# Expected:
# - CPU: 50-80% during test
# - Memory: Stable, no continuous growth
# - Network: Active during model inference
```

### 2. Application Logs

```bash
# Watch main backend logs
docker-compose logs -f fir_pipeline

# Look for:
# - No error messages
# - Successful session creation
# - Model inference completion
# - FIR generation success
```

### 3. Database Connections

```bash
# Check MySQL connections
docker-compose exec mysql mysql -u root -p${MYSQL_PASSWORD} -e "SHOW PROCESSLIST;"

# Expected:
# - Active connections during test
# - Connections released after requests complete
# - No "too many connections" errors
```

### 4. Health Endpoint

```bash
# Monitor health during test
watch -n 2 'curl -s http://localhost:8000/health | jq'

# Expected:
# - status: "healthy" or "degraded"
# - All services operational
# - Concurrency config visible
```

## Troubleshooting

### Issue: Test fails with "Connection refused"

**Cause:** Services not running or not healthy

**Solution:**
```bash
# Check service status
docker-compose ps

# Restart services
docker-compose restart

# Wait for health checks
sleep 60

# Retry test
python test_concurrency.py
```

### Issue: Test fails with "Timeout" errors

**Cause:** Model servers overloaded or slow

**Solution:**
1. Check model server logs:
   ```bash
   docker-compose logs gguf_model_server
   docker-compose logs asr_ocr_model_server
   ```

2. Increase timeout in test:
   ```python
   TEST_TIMEOUT = 90  # Increase from 60
   ```

3. Reduce concurrent requests:
   ```python
   NUM_CONCURRENT_REQUESTS = 5
   ```

### Issue: Test fails with "Database connection" errors

**Cause:** MySQL connection pool exhausted

**Solution:**
1. Increase MySQL pool size in `agentv5.py`:
   ```python
   "pool_size": 20,  # Increase from 15
   ```

2. Restart services:
   ```bash
   docker-compose restart fir_pipeline
   ```

### Issue: Some requests fail randomly

**Cause:** Resource contention or race conditions

**Solution:**
1. Check system resources:
   ```bash
   docker stats
   ```

2. Reduce concurrent requests:
   ```bash
   export MAX_CONCURRENT_REQUESTS=10
   docker-compose restart fir_pipeline
   ```

3. Check for errors in logs:
   ```bash
   docker-compose logs fir_pipeline | grep ERROR
   ```

### Issue: Memory usage grows continuously

**Cause:** Memory leak or insufficient cleanup

**Solution:**
1. Monitor memory over time:
   ```bash
   docker stats --no-stream fir_pipeline
   ```

2. Restart services periodically:
   ```bash
   docker-compose restart
   ```

3. Check for unclosed resources in code

## Performance Benchmarks

### Expected Performance Metrics

| Metric | Target | Acceptable | Poor |
|--------|--------|------------|------|
| Single Request Duration | < 20s | < 30s | > 30s |
| 10 Concurrent Requests Total | < 25s | < 35s | > 40s |
| Success Rate | 100% | > 95% | < 95% |
| Average Request Duration | < 20s | < 25s | > 30s |
| Memory Usage (per request) | < 100MB | < 200MB | > 300MB |
| CPU Usage (during test) | 50-70% | 70-90% | > 90% |

### Baseline Performance

**Hardware:** 4 CPU cores, 8GB RAM

| Test | Requests | Duration | Success Rate | Avg Time |
|------|----------|----------|--------------|----------|
| Single Request | 1 | 18.5s | 100% | 18.5s |
| Concurrent (5) | 5 | 20.2s | 100% | 19.1s |
| Concurrent (10) | 10 | 22.8s | 100% | 19.7s |
| Concurrent (15) | 15 | 28.4s | 100% | 20.3s |
| Concurrent (20) | 20 | 35.6s | 100% | 21.2s |

## Continuous Testing

### Automated Testing

Add to CI/CD pipeline:

```yaml
# .github/workflows/test.yml
name: Concurrency Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Start services
        run: docker-compose up -d
      
      - name: Wait for services
        run: sleep 120
      
      - name: Install test dependencies
        run: pip install -r test_requirements.txt
      
      - name: Run concurrency test
        run: python test_concurrency.py
      
      - name: Upload results
        uses: actions/upload-artifact@v2
        with:
          name: test-results
          path: concurrency_test_results.json
```

### Scheduled Testing

Run tests periodically:

```bash
# Add to crontab
0 */6 * * * cd /path/to/afirgen && python test_concurrency.py >> test.log 2>&1
```

## Conclusion

The concurrency testing validates that the AFIRGen system can:
- âœ… Handle 10+ concurrent FIR generation requests
- âœ… Maintain fast response times (< 30s per request)
- âœ… Achieve high success rates (> 99%)
- âœ… Remain stable under sustained load
- âœ… Efficiently utilize system resources

Regular testing ensures the system continues to meet performance requirements as it evolves.
